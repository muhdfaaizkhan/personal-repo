{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 5px; height: 50px\">\n",
    "\n",
    "# Project 3: Web APIs & NLP\n",
    "\n",
    "### Project Title: Generative AI and Art - understanding and predicting chatter from online communities\n",
    "\n",
    "**DSI-41 Group 2**: Muhammad Faaiz Khan, Lionel Foo, Gabriel Tan\n",
    "\n",
    "## Part 1: Data Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing libaries\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data scraping\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# this setting widens how many characters pandas will display in a column:\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PRAW API\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [PRAW API](https://praw.readthedocs.io/en/stable/) to perform scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique identifier client_id and client_secret retrieved from personal application registered on Reddit.\n",
    "'''\n",
    "Note: You will have to fill in these identifier keys with your own set. Refer to below link:\n",
    "https://praw.readthedocs.io/en/latest/getting_started/authentication.html\n",
    "'''\n",
    "reddit = praw.Reddit(user_agent=\"PRAW\", client_id=\"\", \n",
    "                     client_secret=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraping process is summarised below:\n",
    "1. Define a dictionary where the keys are our column names, with empty lists as the values.\n",
    "2. Loop through all posts in each subreddit, appending the relevant post information into our dictionary with each loop.\n",
    "3. Convert the dictionary to dataframe format and export.\n",
    "\n",
    "The data dictionary for our scraped dataframe is defined below:\n",
    "\n",
    "\n",
    "|Feature|Type|Description|\n",
    "|---|---|---|\n",
    "|`subr-def_ai`|int|Assigned boolean to indicate whether the post is from *r/DefendingAIArt* (1) or *r/ArtistHate* (0)|\n",
    "|`is_op`|int|Assigned boolean, whether the post is the OP* (1) or a comment (0) |\n",
    "|`author`|str|Username of the person making the post|\n",
    "|`post_id`|str|Unique identifier string for each post|\n",
    "|`body`|str|Content of the post**|\n",
    "|`upvotes`|int|Number of upvotes for the post|\n",
    "|`num_comments`|int|Number of direct comments/responses to the post| \n",
    "\n",
    "*OP refers to the original post for each thread.\n",
    "\n",
    "**For the OP, `body` will be a concatenation of both its title and its post content (if any). Comments have no title and thus do not require this concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First defining the dictionary before the scraping process\n",
    "reddit_dict = {'subr-def_ai':[],\n",
    "                'is_op': [],\n",
    "                'author': [],\n",
    "                'post_id': [],\n",
    "                'body': [],\n",
    "                'upvotes': [],\n",
    "                'num_comments': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate in populating our dictionary with the scraped data, we will define the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to append post information to the dictionary\n",
    "def dictapp(dict, post, def_ai=True, op=False):\n",
    "    if op:\n",
    "        dict['is_op'].append(1)\n",
    "        if post.selftext:\n",
    "            dict['body'].append(post.title + ' ' + post.selftext)\n",
    "        else:\n",
    "            dict['body'].append(post.title)\n",
    "    else:\n",
    "        dict['is_op'].append(0)\n",
    "        dict['body'].append(post.body)\n",
    "    dict['author'].append(post.author)\n",
    "    dict['num_comments'].append(replycnt(post, op))\n",
    "    dict['subr-def_ai'].append(int(def_ai))\n",
    "    dict['upvotes'].append(post.score)\n",
    "    dict['post_id'].append(post.id)\n",
    "\n",
    "\n",
    "# Defining function to count replies to comment. This is used in dictapp() above.\n",
    "def replycnt(comment, op):\n",
    "    if op:\n",
    "        reply_obj = comment.comments\n",
    "    else:\n",
    "        reply_obj = comment.replies\n",
    "    count = 0\n",
    "    for reply in reply_obj:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further attributes of the .submission class can be found [here](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html).\n",
    "Further attributes of the .subreddit class can be found [here](https://praw.readthedocs.io/en/stable/code_overview/models/subreddit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start scraping *r/DefendingAIArt* and append the posts to `reddit_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aspire\\AppData\\Local\\Temp\\ipykernel_4736\\3949176417.py:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(\"DefendingAIArt\").top(\"all\"):\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"DefendingAIArt\").top(\"all\"):     # For loop to go through all threads in the subreddit\n",
    "    submission.comments.replace_more(limit=0)                        # Ignores elements that expand the comments on the page\n",
    "    dictapp(reddit_dict, submission, def_ai=True, op=True)           # Appends the OP to the dictionary\n",
    "    for comment in submission.comments.list():\n",
    "        dictapp(reddit_dict, comment, def_ai=True)                   # For loop to append all comments in the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subr-def_ai</th>\n",
       "      <th>is_op</th>\n",
       "      <th>author</th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>101n5dv</td>\n",
       "      <td>[TW: DEATH THREAT] And they say that \"AI bros\" are the ones harassing the artists?</td>\n",
       "      <td>498</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Zinthaniel</td>\n",
       "      <td>j2plqsw</td>\n",
       "      <td>there's no rule in this sub requiring you to hide the tweet handle. So its kind of idiotic to do so, especially when the tweet is glorifying killing people who use AI.</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>j2oryjg</td>\n",
       "      <td>\"Corpos telling modern artists to die\"\\nIT'S FREE AND OPEN SOURCE</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>chillaxinbball</td>\n",
       "      <td>j2rbhzy</td>\n",
       "      <td>Unfortunately there are a few idiots on Twitter that are being rude which is giving the antiai crowd a huge confirmation bias boner. The Anti ai crowd has a hard time separating individuals from the group and seeing that the *majority* of the hateful comments comes from them.</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Trippy-Worlds</td>\n",
       "      <td>j2oyyyb</td>\n",
       "      <td>Why is the username crossed out? They need to be reported on Twitter and probably to the FBI. \\n\\nWould really like to see who all those likes are as well. Please tell us the Twitter ID. Suggesting violence is not permissible!</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subr-def_ai  is_op          author  post_id  \\\n",
       "0            1      1            None  101n5dv   \n",
       "1            1      0      Zinthaniel  j2plqsw   \n",
       "2            1      0            None  j2oryjg   \n",
       "3            1      0  chillaxinbball  j2rbhzy   \n",
       "4            1      0   Trippy-Worlds  j2oyyyb   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                   body  \\\n",
       "0                                                                                                                                                                                                    [TW: DEATH THREAT] And they say that \"AI bros\" are the ones harassing the artists?   \n",
       "1                                                                                                               there's no rule in this sub requiring you to hide the tweet handle. So its kind of idiotic to do so, especially when the tweet is glorifying killing people who use AI.   \n",
       "2                                                                                                                                                                                                                     \"Corpos telling modern artists to die\"\\nIT'S FREE AND OPEN SOURCE   \n",
       "3  Unfortunately there are a few idiots on Twitter that are being rude which is giving the antiai crowd a huge confirmation bias boner. The Anti ai crowd has a hard time separating individuals from the group and seeing that the *majority* of the hateful comments comes from them.   \n",
       "4                                                    Why is the username crossed out? They need to be reported on Twitter and probably to the FBI. \\n\\nWould really like to see who all those likes are as well. Please tell us the Twitter ID. Suggesting violence is not permissible!   \n",
       "\n",
       "   upvotes  num_comments  \n",
       "0      498             9  \n",
       "1       30             1  \n",
       "2       56             2  \n",
       "3       12             0  \n",
       "4       23             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking dataframe\n",
    "pd.DataFrame(reddit_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we repeat the process above to scrape *r/ArtistHate* and append the posts to `reddit_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aspire\\AppData\\Local\\Temp\\ipykernel_4736\\1675939007.py:1: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(\"ArtistHate\").top(\"all\"):\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit(\"ArtistHate\").top(\"all\"):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    dictapp(reddit_dict, submission, def_ai=False, op=True)      # Note that def_ai is set to False in this block as we are scraping r/ArtistHate instead\n",
    "    for comment in submission.comments.list():\n",
    "        dictapp(reddit_dict, comment, def_ai=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subr-def_ai</th>\n",
       "      <th>is_op</th>\n",
       "      <th>author</th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Captain_Pumpkinhead</td>\n",
       "      <td>k45jc10</td>\n",
       "      <td>Yeah, that makes sense.  If you're advertising for a drawing tool like a pen tablet/display, you should definitely be using hand drawn art.  Preferably drawn using the advertised device.</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alkaia1</td>\n",
       "      <td>k471c4e</td>\n",
       "      <td>I am really glad that they did the right thing and terminated their collaboration.</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dontthrowmeaway2023</td>\n",
       "      <td>k48x2bv</td>\n",
       "      <td>phew that´s good to hear :)</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shyraku</td>\n",
       "      <td>k49jjxg</td>\n",
       "      <td>I will remember to look at XXPen's product when my Wacom finally die, I think they deserve that</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WonderfulWanderer777</td>\n",
       "      <td>k45dhqx</td>\n",
       "      <td>Yeah...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subr-def_ai  is_op                author  post_id  \\\n",
       "7784            0      0   Captain_Pumpkinhead  k45jc10   \n",
       "7785            0      0               Alkaia1  k471c4e   \n",
       "7786            0      0   dontthrowmeaway2023  k48x2bv   \n",
       "7787            0      0               Shyraku  k49jjxg   \n",
       "7788            0      0  WonderfulWanderer777  k45dhqx   \n",
       "\n",
       "                                                                                                                                                                                            body  \\\n",
       "7784  Yeah, that makes sense.  If you're advertising for a drawing tool like a pen tablet/display, you should definitely be using hand drawn art.  Preferably drawn using the advertised device.   \n",
       "7785                                                                                                          I am really glad that they did the right thing and terminated their collaboration.   \n",
       "7786                                                                                                                                                                 phew that´s good to hear :)   \n",
       "7787                                                                                             I will remember to look at XXPen's product when my Wacom finally die, I think they deserve that   \n",
       "7788                                                                                                                                                                                     Yeah...   \n",
       "\n",
       "      upvotes  num_comments  \n",
       "7784       20             0  \n",
       "7785       10             0  \n",
       "7786        4             0  \n",
       "7787        2             0  \n",
       "7788       11             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking tail end of dataframe\n",
    "pd.DataFrame(reddit_dict).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary is then converted to a dataframe `reddit_df`, then exported to .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7789 entries, 0 to 7788\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   subr-def_ai   7789 non-null   int64 \n",
      " 1   is_op         7789 non-null   int64 \n",
      " 2   author        7316 non-null   object\n",
      " 3   post_id       7789 non-null   object\n",
      " 4   body          7789 non-null   object\n",
      " 5   upvotes       7789 non-null   int64 \n",
      " 6   num_comments  7789 non-null   int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 426.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe and exporting to csv format\n",
    "reddit_df = pd.DataFrame(reddit_dict)\n",
    "# reddit_df.to_csv('data/reddit_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(DEPRECATED)** Scraping test data from *r/aiwars*\n",
    "___\n",
    "Initial intention was to run the prediction model on scraped data from a seperate third subreddit, *r/aiwars*. Instead of doing so, we will perform live scraping of *r/aiwars* and real-time prediction using Streamlit. Please refer to the python scripts within the streamlit_widget folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = reddit.submission(url='https://www.reddit.com/r/aiwars/comments/17slemz/which_one_is_it_antiai/')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Resetting reddit_dict for scraping r/aiwars\n",
    "# reddit_dict = {'subr-def_ai':[],\n",
    "#                 'is_op': [],\n",
    "#                 'author': [],\n",
    "#                 'post_id': [],\n",
    "#                 'body': [],\n",
    "#                 'upvotes': [],\n",
    "#                 'num_comments': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.comments.replace_more(limit=0)         # Ignores elements that expand the comments on the page\n",
    "# for comment in submission.comments.list():\n",
    "#     dictapp(reddit_dict, comment)                 # For loop to append all comments in the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating dataframe and exporting to csv format\n",
    "# aiwars_df = pd.DataFrame(reddit_dict)\n",
    "# aiwars_df.to_csv('../data/aiwars_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
